{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el viernes 01-agosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 02 de agosto a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Tue Jul 29 01:47:57 2025'"
      ],
      "text/latex": [
       "'Tue Jul 29 01:47:57 2025'"
      ],
      "text/markdown": [
       "'Tue Jul 29 01:47:57 2025'"
      ],
      "text/plain": [
       "[1] \"Tue Jul 29 01:47:57 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 656930</td><td>35.1</td><td>1439371</td><td>76.9</td><td>1431361</td><td>76.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1225015</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924961</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  656930 & 35.1 & 1439371 & 76.9 & 1431361 & 76.5\\\\\n",
       "\tVcells & 1225015 &  9.4 & 8388608 & 64.0 & 1924961 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  656930 | 35.1 | 1439371 | 76.9 | 1431361 | 76.5 |\n",
       "| Vcells | 1225015 |  9.4 | 8388608 | 64.0 | 1924961 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  656930 35.1 1439371    76.9 1431361  76.5\n",
       "Vcells 1225015  9.4 8388608    64.0 1924961  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4940\n",
    "PARAM$semilla_primigenia <- 959659\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-a\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 1200,\n",
    "  learning_rate= 0.02,\n",
    "  feature_fraction= 0.5,\n",
    "  num_leaves= 750,\n",
    "  min_data_in_leaf= 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 100L, upper= 1000L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.02, upper= 0.25),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.5, upper= 0.9),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 31L, upper= 400L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 100L, upper= 5000L)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83912"
      ],
      "text/latex": [
       "83912"
      ],
      "text/markdown": [
       "83912"
      ],
      "text/plain": [
       "[1] 83912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Tue Jul 29 01:55:09 2025 AUC 0.927045099175096\n",
      "\n",
      "Tue Jul 29 01:55:25 2025 AUC 0.925037097822353\n",
      "\n",
      "Tue Jul 29 01:55:45 2025 AUC 0.925486914280162\n",
      "\n",
      "Tue Jul 29 01:56:04 2025 AUC 0.9253088062175\n",
      "\n",
      "Tue Jul 29 01:56:36 2025 AUC 0.926287835422903\n",
      "\n",
      "Tue Jul 29 01:57:02 2025 AUC 0.927461176032853\n",
      "\n",
      "Tue Jul 29 01:57:09 2025 AUC 0.927709273556235\n",
      "\n",
      "Tue Jul 29 01:57:25 2025 AUC 0.924883586717027\n",
      "\n",
      "Tue Jul 29 01:57:56 2025 AUC 0.926308581521121\n",
      "\n",
      "Tue Jul 29 01:58:08 2025 AUC 0.924757584703283\n",
      "\n",
      "Tue Jul 29 01:58:48 2025 AUC 0.924600807099105\n",
      "\n",
      "Tue Jul 29 01:59:17 2025 AUC 0.926412379478774\n",
      "\n",
      "Tue Jul 29 01:59:55 2025 AUC 0.926633632140724\n",
      "\n",
      "Tue Jul 29 02:00:23 2025 AUC 0.918924975911058\n",
      "\n",
      "Tue Jul 29 02:01:16 2025 AUC 0.928012492582478\n",
      "\n",
      "Tue Jul 29 02:01:54 2025 AUC 0.926701622922832\n",
      "\n",
      "Tue Jul 29 02:02:29 2025 AUC 0.920905896129573\n",
      "\n",
      "Tue Jul 29 02:02:40 2025 AUC 0.924451463156398\n",
      "\n",
      "Tue Jul 29 02:03:25 2025 AUC 0.924296083787754\n",
      "\n",
      "Tue Jul 29 02:03:45 2025 AUC 0.924587118564379\n",
      "\n",
      "[mbo] 0: num_iterations=222; learning_rate=0.0964; feature_fraction=0.748; num_leaves=340; min_data_in_leaf=2743 : y = 0.927 : 10.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=468; learning_rate=0.116; feature_fraction=0.807; num_leaves=103; min_data_in_leaf=3445 : y = 0.925 : 15.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=630; learning_rate=0.189; feature_fraction=0.707; num_leaves=236; min_data_in_leaf=3735 : y = 0.925 : 20.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=555; learning_rate=0.18; feature_fraction=0.639; num_leaves=185; min_data_in_leaf=3897 : y = 0.925 : 19.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=771; learning_rate=0.0842; feature_fraction=0.669; num_leaves=365; min_data_in_leaf=2164 : y = 0.926 : 31.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=715; learning_rate=0.0664; feature_fraction=0.781; num_leaves=214; min_data_in_leaf=2493 : y = 0.927 : 25.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=117; learning_rate=0.0578; feature_fraction=0.775; num_leaves=263; min_data_in_leaf=957 : y = 0.928 : 7.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=374; learning_rate=0.167; feature_fraction=0.846; num_leaves=163; min_data_in_leaf=1817 : y = 0.925 : 15.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=445; learning_rate=0.149; feature_fraction=0.618; num_leaves=123; min_data_in_leaf=796 : y = 0.926 : 30.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=284; learning_rate=0.199; feature_fraction=0.577; num_leaves=107; min_data_in_leaf=4470 : y = 0.925 : 12.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=899; learning_rate=0.22; feature_fraction=0.641; num_leaves=386; min_data_in_leaf=1738 : y = 0.925 : 40.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=985; learning_rate=0.107; feature_fraction=0.698; num_leaves=145; min_data_in_leaf=4620 : y = 0.926 : 28.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=803; learning_rate=0.0462; feature_fraction=0.896; num_leaves=71; min_data_in_leaf=1226 : y = 0.927 : 38.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=182; learning_rate=0.215; feature_fraction=0.872; num_leaves=288; min_data_in_leaf=272 : y = 0.919 : 28.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=863; learning_rate=0.0346; feature_fraction=0.59; num_leaves=233; min_data_in_leaf=1507 : y = 0.928 : 52.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=662; learning_rate=0.136; feature_fraction=0.522; num_leaves=316; min_data_in_leaf=4900 : y = 0.927 : 38.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=332; learning_rate=0.244; feature_fraction=0.505; num_leaves=306; min_data_in_leaf=549 : y = 0.921 : 35.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=277; learning_rate=0.0216; feature_fraction=0.738; num_leaves=48; min_data_in_leaf=3218 : y = 0.924 : 11.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=912; learning_rate=0.236; feature_fraction=0.556; num_leaves=65; min_data_in_leaf=4096 : y = 0.924 : 44.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=543; learning_rate=0.132; feature_fraction=0.83; num_leaves=355; min_data_in_leaf=2817 : y = 0.925 : 19.9 secs : initdesign\n",
      "\n",
      "Tue Jul 29 02:04:31 2025 AUC 0.92747338364123\n",
      "\n",
      "[mbo] 1: num_iterations=864; learning_rate=0.0517; feature_fraction=0.5; num_leaves=236; min_data_in_leaf=4181 : y = 0.927 : 45.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:06:15 2025 AUC 0.926569358118342\n",
      "\n",
      "[mbo] 2: num_iterations=749; learning_rate=0.0485; feature_fraction=0.5; num_leaves=235; min_data_in_leaf=154 : y = 0.927 : 103.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 3 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:06:24 2025 AUC 0.918782754054622\n",
      "\n",
      "[mbo] 3: num_iterations=101; learning_rate=0.0275; feature_fraction=0.657; num_leaves=294; min_data_in_leaf=2795 : y = 0.919 : 4.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:06:57 2025 AUC 0.926660755774911\n",
      "\n",
      "[mbo] 4: num_iterations=942; learning_rate=0.039; feature_fraction=0.688; num_leaves=226; min_data_in_leaf=2999 : y = 0.927 : 32.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:07:01 2025 AUC 0.925295053981103\n",
      "\n",
      "[mbo] 5: num_iterations=116; learning_rate=0.072; feature_fraction=0.777; num_leaves=250; min_data_in_leaf=4088 : y = 0.925 : 4.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:07:50 2025 AUC 0.928671171095295\n",
      "\n",
      "[mbo] 6: num_iterations=993; learning_rate=0.0212; feature_fraction=0.776; num_leaves=235; min_data_in_leaf=1388 : y = 0.929 : 47.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:08:35 2025 AUC 0.927694770218957\n",
      "\n",
      "[mbo] 7: num_iterations=994; learning_rate=0.0291; feature_fraction=0.721; num_leaves=241; min_data_in_leaf=1623 : y = 0.928 : 44.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:09:31 2025 AUC 0.929453290860978\n",
      "\n",
      "[mbo] 8: num_iterations=900; learning_rate=0.02; feature_fraction=0.603; num_leaves=158; min_data_in_leaf=977 : y = 0.929 : 54.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:10:29 2025 AUC 0.929382230504742\n",
      "\n",
      "[mbo] 9: num_iterations=998; learning_rate=0.0202; feature_fraction=0.806; num_leaves=186; min_data_in_leaf=950 : y = 0.929 : 57.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:11:41 2025 AUC 0.929974761922523\n",
      "\n",
      "[mbo] 10: num_iterations=1000; learning_rate=0.0215; feature_fraction=0.581; num_leaves=84; min_data_in_leaf=654 : y = 0.93 : 71.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:12:34 2025 AUC 0.929362825914326\n",
      "\n",
      "[mbo] 11: num_iterations=961; learning_rate=0.02; feature_fraction=0.615; num_leaves=62; min_data_in_leaf=232 : y = 0.929 : 52.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:13:27 2025 AUC 0.927901012891823\n",
      "\n",
      "[mbo] 12: num_iterations=1000; learning_rate=0.053; feature_fraction=0.583; num_leaves=84; min_data_in_leaf=1369 : y = 0.928 : 52.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:13:42 2025 AUC 0.927945808344136\n",
      "\n",
      "[mbo] 13: num_iterations=236; learning_rate=0.0803; feature_fraction=0.779; num_leaves=157; min_data_in_leaf=739 : y = 0.928 : 13.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:14:41 2025 AUC 0.928438753005465\n",
      "\n",
      "[mbo] 14: num_iterations=1000; learning_rate=0.02; feature_fraction=0.532; num_leaves=58; min_data_in_leaf=1571 : y = 0.928 : 59.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:15:11 2025 AUC 0.927833687012586\n",
      "\n",
      "[mbo] 15: num_iterations=858; learning_rate=0.0207; feature_fraction=0.797; num_leaves=32; min_data_in_leaf=102 : y = 0.928 : 28.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:15:18 2025 AUC 0.927498031081535\n",
      "\n",
      "[mbo] 16: num_iterations=108; learning_rate=0.0662; feature_fraction=0.502; num_leaves=31; min_data_in_leaf=1139 : y = 0.927 : 6.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:16:41 2025 AUC 0.928893534207079\n",
      "\n",
      "[mbo] 17: num_iterations=1000; learning_rate=0.0201; feature_fraction=0.547; num_leaves=188; min_data_in_leaf=590 : y = 0.929 : 81.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 18 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:16:53 2025 AUC 0.927277877620403\n",
      "\n",
      "[mbo] 18: num_iterations=102; learning_rate=0.103; feature_fraction=0.502; num_leaves=255; min_data_in_leaf=668 : y = 0.927 : 8.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:17:16 2025 AUC 0.928063143006362\n",
      "\n",
      "[mbo] 19: num_iterations=424; learning_rate=0.0601; feature_fraction=0.65; num_leaves=78; min_data_in_leaf=1025 : y = 0.928 : 22.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:17:40 2025 AUC 0.926546713335668\n",
      "\n",
      "[mbo] 20: num_iterations=491; learning_rate=0.0923; feature_fraction=0.5; num_leaves=35; min_data_in_leaf=4934 : y = 0.927 : 23.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:18:22 2025 AUC 0.9303163800094\n",
      "\n",
      "[mbo] 21: num_iterations=1000; learning_rate=0.0201; feature_fraction=0.62; num_leaves=31; min_data_in_leaf=828 : y = 0.93 : 41.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:18:44 2025 AUC 0.926931574061636\n",
      "\n",
      "[mbo] 22: num_iterations=332; learning_rate=0.0863; feature_fraction=0.555; num_leaves=271; min_data_in_leaf=1348 : y = 0.927 : 20.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:19:21 2025 AUC 0.92644890802094\n",
      "\n",
      "[mbo] 23: num_iterations=1000; learning_rate=0.0209; feature_fraction=0.617; num_leaves=94; min_data_in_leaf=3264 : y = 0.926 : 36.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:19:47 2025 AUC 0.925996312795895\n",
      "\n",
      "[mbo] 24: num_iterations=943; learning_rate=0.0531; feature_fraction=0.768; num_leaves=31; min_data_in_leaf=4997 : y = 0.926 : 25.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:20:17 2025 AUC 0.930143071053673\n",
      "\n",
      "[mbo] 25: num_iterations=487; learning_rate=0.0201; feature_fraction=0.53; num_leaves=31; min_data_in_leaf=741 : y = 0.93 : 28.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:20:50 2025 AUC 0.929745786493074\n",
      "\n",
      "[mbo] 26: num_iterations=729; learning_rate=0.0204; feature_fraction=0.614; num_leaves=32; min_data_in_leaf=755 : y = 0.93 : 32.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:21:34 2025 AUC 0.925675509856828\n",
      "\n",
      "[mbo] 27: num_iterations=874; learning_rate=0.0945; feature_fraction=0.503; num_leaves=400; min_data_in_leaf=5000 : y = 0.926 : 43.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:21:47 2025 AUC 0.929398007003157\n",
      "\n",
      "[mbo] 28: num_iterations=215; learning_rate=0.02; feature_fraction=0.571; num_leaves=31; min_data_in_leaf=579 : y = 0.929 : 12.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:22:13 2025 AUC 0.929341381694552\n",
      "\n",
      "[mbo] 29: num_iterations=420; learning_rate=0.0302; feature_fraction=0.501; num_leaves=34; min_data_in_leaf=794 : y = 0.929 : 25.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:23:08 2025 AUC 0.927824368453615\n",
      "\n",
      "[mbo] 30: num_iterations=996; learning_rate=0.0549; feature_fraction=0.85; num_leaves=400; min_data_in_leaf=964 : y = 0.928 : 53.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:24:01 2025 AUC 0.925890623340731\n",
      "\n",
      "[mbo] 31: num_iterations=999; learning_rate=0.0668; feature_fraction=0.506; num_leaves=59; min_data_in_leaf=3296 : y = 0.926 : 52.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:24:58 2025 AUC 0.926886957163941\n",
      "\n",
      "[mbo] 32: num_iterations=1000; learning_rate=0.162; feature_fraction=0.501; num_leaves=31; min_data_in_leaf=945 : y = 0.927 : 57.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:25:51 2025 AUC 0.923269567918105\n",
      "\n",
      "[mbo] 33: num_iterations=1000; learning_rate=0.111; feature_fraction=0.705; num_leaves=73; min_data_in_leaf=100 : y = 0.923 : 51.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:25:59 2025 AUC 0.927035424130123\n",
      "\n",
      "[mbo] 34: num_iterations=101; learning_rate=0.0924; feature_fraction=0.888; num_leaves=400; min_data_in_leaf=662 : y = 0.927 : 6.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:26:35 2025 AUC 0.929891296930439\n",
      "\n",
      "[mbo] 35: num_iterations=534; learning_rate=0.02; feature_fraction=0.622; num_leaves=93; min_data_in_leaf=693 : y = 0.93 : 35.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:26:57 2025 AUC 0.92912176235661\n",
      "\n",
      "[mbo] 36: num_iterations=373; learning_rate=0.02; feature_fraction=0.647; num_leaves=59; min_data_in_leaf=239 : y = 0.929 : 21.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 37 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:27:50 2025 AUC 0.925761253266224\n",
      "\n",
      "[mbo] 37: num_iterations=1000; learning_rate=0.194; feature_fraction=0.507; num_leaves=399; min_data_in_leaf=4999 : y = 0.926 : 49.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:28:57 2025 AUC 0.929517636153039\n",
      "\n",
      "[mbo] 38: num_iterations=998; learning_rate=0.0201; feature_fraction=0.502; num_leaves=44; min_data_in_leaf=832 : y = 0.93 : 66.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:29:03 2025 AUC 0.925282460627861\n",
      "\n",
      "[mbo] 39: num_iterations=102; learning_rate=0.142; feature_fraction=0.501; num_leaves=31; min_data_in_leaf=4967 : y = 0.925 : 5.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:30:14 2025 AUC 0.924117672831187\n",
      "\n",
      "[mbo] 40: num_iterations=998; learning_rate=0.163; feature_fraction=0.5; num_leaves=374; min_data_in_leaf=1238 : y = 0.924 : 69.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:30:22 2025 AUC 0.926634387471216\n",
      "\n",
      "[mbo] 41: num_iterations=105; learning_rate=0.127; feature_fraction=0.501; num_leaves=31; min_data_in_leaf=1565 : y = 0.927 : 7.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:30:45 2025 AUC 0.930490334982543\n",
      "\n",
      "[mbo] 42: num_iterations=416; learning_rate=0.02; feature_fraction=0.582; num_leaves=35; min_data_in_leaf=924 : y = 0.93 : 22.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:31:46 2025 AUC 0.924607895515902\n",
      "\n",
      "[mbo] 43: num_iterations=475; learning_rate=0.0512; feature_fraction=0.9; num_leaves=246; min_data_in_leaf=125 : y = 0.925 : 60.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:32:16 2025 AUC 0.925187059688245\n",
      "\n",
      "[mbo] 44: num_iterations=1000; learning_rate=0.155; feature_fraction=0.67; num_leaves=32; min_data_in_leaf=4994 : y = 0.925 : 28.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:32:40 2025 AUC 0.92485576742455\n",
      "\n",
      "[mbo] 45: num_iterations=885; learning_rate=0.25; feature_fraction=0.9; num_leaves=400; min_data_in_leaf=4998 : y = 0.925 : 23.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:32:56 2025 AUC 0.930049750975739\n",
      "\n",
      "[mbo] 46: num_iterations=370; learning_rate=0.02; feature_fraction=0.873; num_leaves=32; min_data_in_leaf=936 : y = 0.93 : 15.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:33:14 2025 AUC 0.929655611379072\n",
      "\n",
      "[mbo] 47: num_iterations=451; learning_rate=0.02; feature_fraction=0.741; num_leaves=31; min_data_in_leaf=975 : y = 0.93 : 17.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:33:41 2025 AUC 0.926463170778335\n",
      "\n",
      "[mbo] 48: num_iterations=1000; learning_rate=0.0673; feature_fraction=0.898; num_leaves=318; min_data_in_leaf=5000 : y = 0.926 : 25.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:34:27 2025 AUC 0.923663627174082\n",
      "\n",
      "[mbo] 49: num_iterations=849; learning_rate=0.195; feature_fraction=0.501; num_leaves=31; min_data_in_leaf=126 : y = 0.924 : 45.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:34:33 2025 AUC 0.925186770201606\n",
      "\n",
      "[mbo] 50: num_iterations=108; learning_rate=0.25; feature_fraction=0.578; num_leaves=398; min_data_in_leaf=4973 : y = 0.925 : 5.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:34:38 2025 AUC 0.922261773546134\n",
      "\n",
      "[mbo] 51: num_iterations=112; learning_rate=0.0201; feature_fraction=0.881; num_leaves=31; min_data_in_leaf=797 : y = 0.922 : 4.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:35:14 2025 AUC 0.927832337727422\n",
      "\n",
      "[mbo] 52: num_iterations=595; learning_rate=0.02; feature_fraction=0.529; num_leaves=36; min_data_in_leaf=1343 : y = 0.928 : 35.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:35:36 2025 AUC 0.928589910842144\n",
      "\n",
      "[mbo] 53: num_iterations=410; learning_rate=0.02; feature_fraction=0.81; num_leaves=156; min_data_in_leaf=1038 : y = 0.929 : 20.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:35:49 2025 AUC 0.926395032235084\n",
      "\n",
      "[mbo] 54: num_iterations=195; learning_rate=0.0568; feature_fraction=0.584; num_leaves=69; min_data_in_leaf=111 : y = 0.926 : 12.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:36:07 2025 AUC 0.929659719583073\n",
      "\n",
      "[mbo] 55: num_iterations=343; learning_rate=0.0201; feature_fraction=0.581; num_leaves=32; min_data_in_leaf=720 : y = 0.93 : 17.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:36:43 2025 AUC 0.930369757403866\n",
      "\n",
      "[mbo] 56: num_iterations=962; learning_rate=0.0236; feature_fraction=0.686; num_leaves=31; min_data_in_leaf=782 : y = 0.93 : 35.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:37:01 2025 AUC 0.929095472113955\n",
      "\n",
      "[mbo] 57: num_iterations=453; learning_rate=0.0201; feature_fraction=0.893; num_leaves=31; min_data_in_leaf=957 : y = 0.929 : 17.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 58 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:37:28 2025 AUC 0.925567055330273\n",
      "\n",
      "[mbo] 58: num_iterations=427; learning_rate=0.0201; feature_fraction=0.524; num_leaves=31; min_data_in_leaf=3729 : y = 0.926 : 22.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:38:14 2025 AUC 0.92916874101095\n",
      "\n",
      "[mbo] 59: num_iterations=987; learning_rate=0.02; feature_fraction=0.733; num_leaves=43; min_data_in_leaf=730 : y = 0.929 : 44.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:38:57 2025 AUC 0.930377893188421\n",
      "\n",
      "[mbo] 60: num_iterations=955; learning_rate=0.0265; feature_fraction=0.613; num_leaves=31; min_data_in_leaf=882 : y = 0.93 : 41.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:39:20 2025 AUC 0.930587129450019\n",
      "\n",
      "[mbo] 61: num_iterations=458; learning_rate=0.0204; feature_fraction=0.599; num_leaves=31; min_data_in_leaf=732 : y = 0.931 : 22.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:40:06 2025 AUC 0.929570142324286\n",
      "\n",
      "[mbo] 62: num_iterations=783; learning_rate=0.0243; feature_fraction=0.667; num_leaves=136; min_data_in_leaf=821 : y = 0.93 : 44.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:40:20 2025 AUC 0.927401000764383\n",
      "\n",
      "[mbo] 63: num_iterations=308; learning_rate=0.0632; feature_fraction=0.877; num_leaves=32; min_data_in_leaf=1726 : y = 0.927 : 13.0 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:40:54 2025 AUC 0.930418299207077\n",
      "\n",
      "[mbo] 64: num_iterations=891; learning_rate=0.0241; feature_fraction=0.656; num_leaves=32; min_data_in_leaf=871 : y = 0.93 : 32.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:41:32 2025 AUC 0.93057512214769\n",
      "\n",
      "[mbo] 65: num_iterations=1000; learning_rate=0.0245; feature_fraction=0.646; num_leaves=31; min_data_in_leaf=798 : y = 0.931 : 36.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:41:54 2025 AUC 0.926930647480641\n",
      "\n",
      "[mbo] 66: num_iterations=685; learning_rate=0.0635; feature_fraction=0.626; num_leaves=364; min_data_in_leaf=5000 : y = 0.927 : 21.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:42:16 2025 AUC 0.929562521830493\n",
      "\n",
      "[mbo] 67: num_iterations=492; learning_rate=0.0237; feature_fraction=0.625; num_leaves=32; min_data_in_leaf=865 : y = 0.93 : 20.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:43:08 2025 AUC 0.930586887197436\n",
      "\n",
      "[mbo] 68: num_iterations=961; learning_rate=0.0238; feature_fraction=0.648; num_leaves=63; min_data_in_leaf=864 : y = 0.931 : 50.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:43:45 2025 AUC 0.92911268034693\n",
      "\n",
      "[mbo] 69: num_iterations=440; learning_rate=0.02; feature_fraction=0.522; num_leaves=270; min_data_in_leaf=595 : y = 0.929 : 35.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:44:40 2025 AUC 0.929194260516488\n",
      "\n",
      "[mbo] 70: num_iterations=963; learning_rate=0.0216; feature_fraction=0.9; num_leaves=399; min_data_in_leaf=903 : y = 0.929 : 54.3 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:45:30 2025 AUC 0.929768022953383\n",
      "\n",
      "[mbo] 71: num_iterations=679; learning_rate=0.02; feature_fraction=0.639; num_leaves=296; min_data_in_leaf=571 : y = 0.93 : 48.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:46:15 2025 AUC 0.927490055126957\n",
      "\n",
      "[mbo] 72: num_iterations=720; learning_rate=0.0201; feature_fraction=0.826; num_leaves=399; min_data_in_leaf=861 : y = 0.927 : 44.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:46:56 2025 AUC 0.92957764978056\n",
      "\n",
      "[mbo] 73: num_iterations=877; learning_rate=0.0246; feature_fraction=0.631; num_leaves=35; min_data_in_leaf=629 : y = 0.93 : 39.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:47:06 2025 AUC 0.924769825310199\n",
      "\n",
      "[mbo] 74: num_iterations=100; learning_rate=0.122; feature_fraction=0.747; num_leaves=217; min_data_in_leaf=597 : y = 0.925 : 9.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 75 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:47:51 2025 AUC 0.927546776912246\n",
      "\n",
      "[mbo] 75: num_iterations=927; learning_rate=0.0239; feature_fraction=0.659; num_leaves=32; min_data_in_leaf=1042 : y = 0.928 : 39.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:48:53 2025 AUC 0.929746809174079\n",
      "\n",
      "[mbo] 76: num_iterations=908; learning_rate=0.0256; feature_fraction=0.611; num_leaves=144; min_data_in_leaf=808 : y = 0.93 : 60.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:49:19 2025 AUC 0.929777484629275\n",
      "\n",
      "[mbo] 77: num_iterations=442; learning_rate=0.0212; feature_fraction=0.614; num_leaves=47; min_data_in_leaf=541 : y = 0.93 : 25.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:50:02 2025 AUC 0.93094848994226\n",
      "\n",
      "[mbo] 78: num_iterations=687; learning_rate=0.0234; feature_fraction=0.503; num_leaves=34; min_data_in_leaf=781 : y = 0.931 : 41.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:50:54 2025 AUC 0.929601031310812\n",
      "\n",
      "[mbo] 79: num_iterations=663; learning_rate=0.0234; feature_fraction=0.501; num_leaves=64; min_data_in_leaf=653 : y = 0.93 : 50.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:51:32 2025 AUC 0.92845981753283\n",
      "\n",
      "[mbo] 80: num_iterations=691; learning_rate=0.0239; feature_fraction=0.584; num_leaves=109; min_data_in_leaf=1654 : y = 0.928 : 36.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:52:22 2025 AUC 0.928778947112634\n",
      "\n",
      "[mbo] 81: num_iterations=685; learning_rate=0.0206; feature_fraction=0.548; num_leaves=88; min_data_in_leaf=886 : y = 0.929 : 49.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:53:20 2025 AUC 0.930152826556921\n",
      "\n",
      "[mbo] 82: num_iterations=981; learning_rate=0.0378; feature_fraction=0.53; num_leaves=31; min_data_in_leaf=781 : y = 0.93 : 56.7 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:54:21 2025 AUC 0.92821061694855\n",
      "\n",
      "[mbo] 83: num_iterations=965; learning_rate=0.0309; feature_fraction=0.635; num_leaves=84; min_data_in_leaf=110 : y = 0.928 : 59.6 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:55:12 2025 AUC 0.930056810280454\n",
      "\n",
      "[mbo] 84: num_iterations=861; learning_rate=0.02; feature_fraction=0.681; num_leaves=280; min_data_in_leaf=886 : y = 0.93 : 50.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:55:35 2025 AUC 0.928194693320574\n",
      "\n",
      "[mbo] 85: num_iterations=369; learning_rate=0.0208; feature_fraction=0.655; num_leaves=211; min_data_in_leaf=937 : y = 0.928 : 21.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:56:31 2025 AUC 0.929877549940988\n",
      "\n",
      "[mbo] 86: num_iterations=698; learning_rate=0.0303; feature_fraction=0.508; num_leaves=76; min_data_in_leaf=655 : y = 0.93 : 54.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:57:00 2025 AUC 0.929468448122249\n",
      "\n",
      "[mbo] 87: num_iterations=668; learning_rate=0.0404; feature_fraction=0.655; num_leaves=34; min_data_in_leaf=774 : y = 0.929 : 28.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:57:31 2025 AUC 0.929130928903131\n",
      "\n",
      "[mbo] 88: num_iterations=688; learning_rate=0.0252; feature_fraction=0.597; num_leaves=31; min_data_in_leaf=289 : y = 0.929 : 30.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 89 in the file bayesiana.RDATA.\n",
      "\n",
      "Tue Jul 29 02:58:25 2025 AUC 0.93094003342652\n",
      "\n",
      "[mbo] 89: num_iterations=799; learning_rate=0.0268; feature_fraction=0.5; num_leaves=31; min_data_in_leaf=809 : y = 0.931 : 46.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:59:15 2025 AUC 0.928999089697361\n",
      "\n",
      "[mbo] 90: num_iterations=791; learning_rate=0.0333; feature_fraction=0.501; num_leaves=41; min_data_in_leaf=780 : y = 0.929 : 49.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 02:59:57 2025 AUC 0.927429274090344\n",
      "\n",
      "[mbo] 91: num_iterations=693; learning_rate=0.0439; feature_fraction=0.502; num_leaves=65; min_data_in_leaf=1888 : y = 0.927 : 40.9 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:00:46 2025 AUC 0.92945110255362\n",
      "\n",
      "[mbo] 92: num_iterations=826; learning_rate=0.0208; feature_fraction=0.669; num_leaves=197; min_data_in_leaf=838 : y = 0.929 : 48.1 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:01:56 2025 AUC 0.928604921430311\n",
      "\n",
      "[mbo] 93: num_iterations=729; learning_rate=0.0232; feature_fraction=0.5; num_leaves=301; min_data_in_leaf=414 : y = 0.929 : 68.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:02:39 2025 AUC 0.927547006182178\n",
      "\n",
      "[mbo] 94: num_iterations=595; learning_rate=0.0238; feature_fraction=0.702; num_leaves=387; min_data_in_leaf=559 : y = 0.928 : 42.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:03:35 2025 AUC 0.928300463411386\n",
      "\n",
      "[mbo] 95: num_iterations=892; learning_rate=0.0218; feature_fraction=0.653; num_leaves=90; min_data_in_leaf=709 : y = 0.928 : 54.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:04:32 2025 AUC 0.929391023583784\n",
      "\n",
      "[mbo] 96: num_iterations=970; learning_rate=0.0231; feature_fraction=0.618; num_leaves=292; min_data_in_leaf=897 : y = 0.929 : 56.5 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:04:59 2025 AUC 0.924342906368657\n",
      "\n",
      "[mbo] 97: num_iterations=756; learning_rate=0.216; feature_fraction=0.695; num_leaves=62; min_data_in_leaf=2781 : y = 0.924 : 25.8 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:06:02 2025 AUC 0.929475179724012\n",
      "\n",
      "[mbo] 98: num_iterations=967; learning_rate=0.0255; feature_fraction=0.61; num_leaves=138; min_data_in_leaf=858 : y = 0.929 : 61.2 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:06:48 2025 AUC 0.928099505901618\n",
      "\n",
      "[mbo] 99: num_iterations=904; learning_rate=0.0255; feature_fraction=0.75; num_leaves=261; min_data_in_leaf=849 : y = 0.928 : 45.4 secs : infill_ei\n",
      "\n",
      "Tue Jul 29 03:07:19 2025 AUC 0.927439514681354\n",
      "\n",
      "[mbo] 100: num_iterations=635; learning_rate=0.0205; feature_fraction=0.865; num_leaves=57; min_data_in_leaf=1017 : y = 0.927 : 29.8 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMHh7uNVIJkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
